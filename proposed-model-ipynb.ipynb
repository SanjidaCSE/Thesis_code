{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934},{"sourceId":6496514,"sourceType":"datasetVersion","datasetId":3754858}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow as tf\n\n# Prevent GPU memory pre-allocation\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(f\"‚ùå Could not set memory growth: {e}\")\n\n# Optional: force TensorFlow to allow GPU growth\nos.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:18:41.594848Z","iopub.execute_input":"2025-06-14T00:18:41.595138Z","iopub.status.idle":"2025-06-14T00:18:50.292537Z","shell.execute_reply.started":"2025-06-14T00:18:41.5951Z","shell.execute_reply":"2025-06-14T00:18:50.291562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! pip install imutils\n\nimport tensorflow as tf\nfrom sklearn.utils.class_weight import compute_class_weight\nimport matplotlib.pyplot as plt\nimport imutils\nimport pathlib\nimport time\nimport PIL as pil\nimport shutil\nfrom tqdm import tqdm\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport gc\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport itertools\nimport joblib\n\n\n\nIMAGE_SIZE = (224, 224)\nBASE_LR = 2e-5\nEPOCH = 20\nBATCH_SIZE = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:18:50.294518Z","iopub.execute_input":"2025-06-14T00:18:50.295016Z","iopub.status.idle":"2025-06-14T00:19:01.549214Z","shell.execute_reply.started":"2025-06-14T00:18:50.294991Z","shell.execute_reply":"2025-06-14T00:19:01.54823Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install tensorflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:19:01.550529Z","iopub.execute_input":"2025-06-14T00:19:01.550785Z","iopub.status.idle":"2025-06-14T00:19:09.874062Z","shell.execute_reply.started":"2025-06-14T00:19:01.550762Z","shell.execute_reply":"2025-06-14T00:19:09.872882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def crop_img(img, image_size=(224, 224)):\n    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n\n    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n    thresh = cv2.erode(thresh, None, iterations=2)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    cnts = imutils.grab_contours(cnts)\n    \n    if len(cnts) == 0:\n        print(\"Warning: No contours found, returning resized original image.\")\n        return cv2.resize(img, image_size, interpolation=cv2.INTER_CUBIC)\n    \n    c = max(cnts, key=cv2.contourArea)\n\n    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n    extRight = tuple(c[c[:, :, 0].argmax()][0])\n    extTop = tuple(c[c[:, :, 1].argmin()][0])\n    extBot = tuple(c[c[:, :, 1].argmax()][0])\n\n    ADD_PIXELS = 0\n    new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n    new_img = cv2.resize(new_img, image_size, interpolation=cv2.INTER_CUBIC)\n    return new_img\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:19:09.875508Z","iopub.execute_input":"2025-06-14T00:19:09.875807Z","iopub.status.idle":"2025-06-14T00:19:09.885073Z","shell.execute_reply.started":"2025-06-14T00:19:09.875781Z","shell.execute_reply":"2025-06-14T00:19:09.884285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def image_preprocessing(source_dir, saved_root_dir, image_size=(224, 224), channels=3):\n    if not os.path.exists(source_dir):\n        raise Exception(f\"Source directory: {source_dir} does not exist\")\n    if not os.path.isdir(source_dir):\n        raise Exception(f\"Source path: {source_dir} is not a directory\")\n\n    if not os.path.exists(saved_root_dir):\n        os.makedirs(saved_root_dir)\n        \n    source_dir_path = pathlib.Path(source_dir)\n    \n    for p in tqdm(source_dir_path.iterdir(), desc=\"Processing folders\"):\n        dir_name = str(p).split(\"/\")[-1]\n        for fp in p.iterdir():\n            filename = str(fp).split(\"/\")[-1]\n\n            img = tf.io.read_file(str(fp))\n            img = tf.image.decode_jpeg(img, channels=channels)\n            img = crop_img(img.numpy(), image_size)\n            img = pil.Image.fromarray(img)\n\n            saved_dist_dir = os.path.join(saved_root_dir, dir_name)\n            if not os.path.exists(saved_dist_dir):\n                os.makedirs(saved_dist_dir)\n\n            img_dist_path = os.path.join(saved_dist_dir, filename)\n            img.save(img_dist_path)\n    print(f\"\\n‚úÖ All images processed and saved to: {saved_root_dir}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:19:09.886183Z","iopub.execute_input":"2025-06-14T00:19:09.886418Z","iopub.status.idle":"2025-06-14T00:19:09.899593Z","shell.execute_reply.started":"2025-06-14T00:19:09.886399Z","shell.execute_reply":"2025-06-14T00:19:09.898732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_preprocessing(\n    \"/kaggle/input/brain-tumor-mri-dataset/Training\",\n    \"/kaggle/working/processed/Training\",\n    image_size=IMAGE_SIZE\n)\n\nimage_preprocessing(\n    \"/kaggle/input/brain-tumor-mri-dataset/Testing\",\n    \"/kaggle/working/processed/Testing\",\n    image_size=IMAGE_SIZE\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:19:09.900982Z","iopub.execute_input":"2025-06-14T00:19:09.901262Z","iopub.status.idle":"2025-06-14T00:20:14.117416Z","shell.execute_reply.started":"2025-06-14T00:19:09.901236Z","shell.execute_reply":"2025-06-14T00:20:14.116509Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Datasets","metadata":{"id":"YuJXo3b-f7PX"}},{"cell_type":"code","source":"root_dir_path = \"/kaggle/working/brain-tumor-mri-dataset\"","metadata":{"id":"nLLkxrD0ivtJ","trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:20:14.11988Z","iopub.execute_input":"2025-06-14T00:20:14.120157Z","iopub.status.idle":"2025-06-14T00:20:14.124071Z","shell.execute_reply.started":"2025-06-14T00:20:14.120135Z","shell.execute_reply":"2025-06-14T00:20:14.123162Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = tf.keras.utils.image_dataset_from_directory(\n    \"/kaggle/working/processed/Training\",\n    label_mode=\"categorical\",\n    batch_size=BATCH_SIZE,\n    image_size=IMAGE_SIZE,\n    seed=42\n)\n\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n    \"/kaggle/working/processed/Testing\",\n    label_mode=\"categorical\",\n    batch_size=BATCH_SIZE,\n    image_size=IMAGE_SIZE,\n    shuffle=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:20:14.125022Z","iopub.execute_input":"2025-06-14T00:20:14.125309Z","iopub.status.idle":"2025-06-14T00:20:14.550302Z","shell.execute_reply.started":"2025-06-14T00:20:14.125284Z","shell.execute_reply":"2025-06-14T00:20:14.549449Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint(\"Class names:\", class_names)\n\ncls_to_id = {c: i for i, c in enumerate(class_names)}\nid_to_cls = {i: c for i, c in enumerate(class_names)}\nprint(\"cls_to_id:\", cls_to_id)\nprint(\"id_to_cls:\", id_to_cls)","metadata":{"id":"8Q3yArLCf7Pe","outputId":"6a76410d-f086-4531-b6cc-6599f0fb2512","trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:20:14.551321Z","iopub.execute_input":"2025-06-14T00:20:14.551533Z","iopub.status.idle":"2025-06-14T00:20:14.556952Z","shell.execute_reply.started":"2025-06-14T00:20:14.551514Z","shell.execute_reply":"2025-06-14T00:20:14.555948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"class_to_id.txt\", \"w\") as f:\n    for k, v in cls_to_id.items():\n        f.write(f\"{k}\\t{v}\\n\")\n\nwith open(\"id_to_class.txt\", \"w\") as f:\n    for k, v in id_to_cls.items():\n        f.write(f\"{k}\\t{v}\\n\")","metadata":{"id":"uPjSeagdf7Pf","trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:20:14.558019Z","iopub.execute_input":"2025-06-14T00:20:14.558283Z","iopub.status.idle":"2025-06-14T00:20:14.574286Z","shell.execute_reply.started":"2025-06-14T00:20:14.558262Z","shell.execute_reply":"2025-06-14T00:20:14.573555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"class_to_id.txt\", \"r\") as f:\n    for line in f.readlines():\n        cls, label = line.replace(\"\\n\",\"\").split(\"\\t\")\n        print(cls, int(label))\nprint(\"\\n\")\nwith open(\"id_to_class.txt\", \"r\") as f:\n    for line in f.readlines():\n        label, cls = line.replace(\"\\n\",\"\").split(\"\\t\")\n        print(int(label), cls)","metadata":{"id":"XLvvdUm6f7Pf","outputId":"b2aa2166-813d-42a6-fb31-2d166c69afbf","trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:20:14.5752Z","iopub.execute_input":"2025-06-14T00:20:14.575508Z","iopub.status.idle":"2025-06-14T00:20:14.587626Z","shell.execute_reply.started":"2025-06-14T00:20:14.57548Z","shell.execute_reply":"2025-06-14T00:20:14.586873Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def class_weight_from_one_hot(ds):\n    class_labels = []\n    if ds.__class__.__name__ == \"_BatchDataset\":\n        ds = ds.unbatch()\n\n    for _, onehot in ds:\n        label = tf.argmax(onehot).numpy()\n        if label.shape == ():  # scalar\n            class_labels.append(label.item())\n        else:  # batch\n            class_labels.extend([l.item() for l in label])\n\n    unique_classes = np.unique(class_labels)\n    class_weights = compute_class_weight(class_weight=\"balanced\", \n                                         classes=unique_classes,\n                                         y=class_labels)\n    return {i: w for i, w in enumerate(class_weights)}\n\n\n    \nclass_weights = class_weight_from_one_hot(train_ds)\nprint(class_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:20:14.588499Z","iopub.execute_input":"2025-06-14T00:20:14.588759Z","iopub.status.idle":"2025-06-14T00:20:18.908077Z","shell.execute_reply.started":"2025-06-14T00:20:14.588727Z","shell.execute_reply":"2025-06-14T00:20:18.907209Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for images, labels in train_ds.take(1):\n    image, label = images[0], labels[0]\n    plt.figure()\n    plt.imshow(tf.cast(image, tf.uint8))\n    plt.title(class_names[tf.argmax(label).numpy()])\n    plt.axis(\"off\")\n    plt.show()\n","metadata":{"id":"f2EnMhWWf7Pf","outputId":"b33194ba-2d4f-4efa-ce72-84677d5d64ba","trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:20:18.909195Z","iopub.execute_input":"2025-06-14T00:20:18.909465Z","iopub.status.idle":"2025-06-14T00:20:19.323446Z","shell.execute_reply.started":"2025-06-14T00:20:18.909441Z","shell.execute_reply":"2025-06-14T00:20:19.32254Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Define augmentation for training data\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,          # Normalization\n    rotation_range=12,       # Random rotation up to 12 degrees\n    zoom_range=0.2,          # Random zoom up to 20%\n    horizontal_flip=True     # Random horizontal flip\n)\n\n# For validation/testing (only normalization)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Create generators using flow_from_directory (no need for dataframes)\ntrain_gen = train_datagen.flow_from_directory(\n    \"/kaggle/working/processed/Training\",\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True\n)\n\ntest_gen = test_datagen.flow_from_directory(\n    \"/kaggle/working/processed/Testing\",\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False\n)\n\nclasses = list(test_gen.class_indices.keys())\nglobal classes \n\n# Update your class names from the generator\nclass_names = list(train_gen.class_indices.keys())\nprint(\"Class names:\", class_names)\n# Update class weight calculation using generator classes\nclass_weights = compute_class_weight(\n    'balanced',\n    classes=np.unique(train_gen.classes),\n    y=train_gen.classes\n)\nclass_weights = dict(enumerate(class_weights))\nprint(\"Class weights:\", class_weights)\n\n# Update your visualization code\nfor images, labels in train_gen:\n    plt.figure(figsize=(10, 10))\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i])\n        plt.title(class_names[np.argmax(labels[i])])\n        plt.axis(\"off\")\n    break  # Just show first batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:20:19.324497Z","iopub.execute_input":"2025-06-14T00:20:19.324735Z","iopub.status.idle":"2025-06-14T00:20:19.329489Z","shell.execute_reply.started":"2025-06-14T00:20:19.324714Z","shell.execute_reply":"2025-06-14T00:20:19.328725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GAM(tf.keras.layers.Layer):\n    def __init__(self, reduction_ratio=16, **kwargs):\n        super(GAM, self).__init__(**kwargs)\n        self.reduction_ratio = reduction_ratio\n\n    def build(self, input_shape):\n        channels = input_shape[-1]\n        self.channel_mlp = tf.keras.Sequential([\n            tf.keras.layers.Dense(channels // self.reduction_ratio, activation='relu'),\n            tf.keras.layers.Dense(channels)\n        ])\n        self.spatial_conv = tf.keras.Sequential([\n            tf.keras.layers.Conv2D(channels // self.reduction_ratio, 7, padding='same', activation='relu'),\n            tf.keras.layers.Conv2D(1, 7, padding='same', activation='sigmoid')\n        ])\n\n    def call(self, inputs):\n        # Channel attention\n        channel_att = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n        channel_att = self.channel_mlp(channel_att)\n\n        # Spatial attention\n        spatial_att = self.spatial_conv(inputs)\n\n        return inputs * channel_att * spatial_att\n\nclass ECA(tf.keras.layers.Layer):\n    def __init__(self, gamma=2, b=1, **kwargs):\n        super(ECA, self).__init__(**kwargs)\n        self.gamma = gamma\n        self.b = b\n\n    def build(self, input_shape):\n        channels = input_shape[-1]\n        self.kernel_size = int(abs((tf.math.log(tf.cast(channels, tf.float32), 2) + self.b) / self.gamma))\n        self.kernel_size = self.kernel_size if self.kernel_size % 2 else self.kernel_size + 1\n        self.conv = tf.keras.layers.Conv1D(1, kernel_size=self.kernel_size, padding='same', use_bias=False)\n\n    def call(self, inputs):\n        # Global Average Pooling (Keep Channel Dimension)\n        x = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n\n        # Reshape for Conv1D\n        x = tf.squeeze(x, axis=[1, 2])\n        x = tf.expand_dims(x, axis=-1)\n\n        # Apply 1D Convolution for Channel Attention\n        x = self.conv(x)\n        x = tf.sigmoid(x)\n\n        # Reshape to match original input dimensions\n        x = tf.reshape(x, [-1, 1, 1, inputs.shape[-1]])\n\n        return inputs * x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:20:19.330862Z","iopub.execute_input":"2025-06-14T00:20:19.331273Z","iopub.status.idle":"2025-06-14T00:20:19.349185Z","shell.execute_reply.started":"2025-06-14T00:20:19.331242Z","shell.execute_reply":"2025-06-14T00:20:19.348404Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model \n\nEfficientNetV2","metadata":{"id":"bFFWroJEf7Pg"}},{"cell_type":"code","source":"from tensorflow.keras import regularizers\n\ndef create_model():\n    inputs = tf.keras.layers.Input(shape=(224, 224, 3))\n    \n    # Enhanced base model configuration\n    base_model = tf.keras.applications.EfficientNetV2B0(\n        include_top=False, \n        weights='imagenet',\n        input_tensor=inputs\n    )\n    base_model.trainable = True\n    \n    # Attention-enhanced flow\n    x = base_model(inputs)\n    x = GAM(reduction_ratio=32)(x)  # Requires 4D input (batch, height, width, channels)\n    x = ECA()(x)\n    \n    # Enhanced head from Part B\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n    x = tf.keras.layers.Dense(256, activation='relu',\n                            kernel_regularizer=regularizers.l2(0.016),\n                            activity_regularizer=regularizers.l1(0.006),\n                            bias_regularizer=regularizers.l1(0.006))(x)\n    x = tf.keras.layers.Dropout(0.45)(x)\n    outputs = tf.keras.layers.Dense(4, \"softmax\")(x)\n    \n    return tf.keras.Model(inputs, outputs)\n\n \n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:20:19.350063Z","iopub.execute_input":"2025-06-14T00:20:19.350303Z","iopub.status.idle":"2025-06-14T00:20:19.363997Z","shell.execute_reply.started":"2025-06-14T00:20:19.350284Z","shell.execute_reply":"2025-06-14T00:20:19.363216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_baseline_model():\n    inputs = tf.keras.layers.Input(shape=(224, 224, 3))\n    \n    # Baseline with Part B enhancements\n    base_model = tf.keras.applications.EfficientNetV2B0(\n        include_top=False, \n        weights='imagenet',\n        input_tensor=inputs\n    )\n    base_model.trainable = True\n    \n    x = base_model(inputs)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n    x = tf.keras.layers.Dense(256, activation='relu',\n                            kernel_regularizer=regularizers.l2(0.016),\n                            activity_regularizer=regularizers.l1(0.006),\n                            bias_regularizer=regularizers.l1(0.006))(x)\n    x = tf.keras.layers.Dropout(0.45)(x)\n    outputs = tf.keras.layers.Dense(4, \"softmax\")(x)\n    \n    return tf.keras.Model(inputs, outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:20:19.364943Z","iopub.execute_input":"2025-06-14T00:20:19.365241Z","iopub.status.idle":"2025-06-14T00:20:19.379015Z","shell.execute_reply.started":"2025-06-14T00:20:19.365212Z","shell.execute_reply":"2025-06-14T00:20:19.378326Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{"id":"8XEQ_expf7Ph"}},{"cell_type":"code","source":"def build_lrfn(lr_start=2e-5, lr_max=1e-3,\n               lr_min=1e-6, lr_rampup_epochs=8,\n               lr_sustain_epochs=0, lr_exp_decay=0.8):\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * \\\n                 lr_exp_decay ** (epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n        return lr\n\n    return lrfn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:20:19.379758Z","iopub.execute_input":"2025-06-14T00:20:19.380046Z","iopub.status.idle":"2025-06-14T00:20:19.393622Z","shell.execute_reply.started":"2025-06-14T00:20:19.380026Z","shell.execute_reply":"2025-06-14T00:20:19.392864Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\n# Remove previous best model file if it exists\nif os.path.exists(\"best_initial_model.keras\"):\n    os.remove(\"best_initial_model.keras\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:20:19.394464Z","iopub.execute_input":"2025-06-14T00:20:19.394732Z","iopub.status.idle":"2025-06-14T00:20:19.404066Z","shell.execute_reply.started":"2025-06-14T00:20:19.394712Z","shell.execute_reply":"2025-06-14T00:20:19.403427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class PrintLR(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        lr = self.model.optimizer.lr\n        if hasattr(lr, 'numpy'):\n            lr = lr.numpy()\n        print(f\"üîÅ Epoch {epoch+1}: Learning rate is {lr:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:20:19.404905Z","iopub.execute_input":"2025-06-14T00:20:19.405129Z","iopub.status.idle":"2025-06-14T00:20:19.417967Z","shell.execute_reply.started":"2025-06-14T00:20:19.40511Z","shell.execute_reply":"2025-06-14T00:20:19.417182Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nimport gc\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nfrom collections import defaultdict\n\n# === Assumes the following are defined ===\n# BASE_LR, build_lrfn(), class_weights, train_ds, test_ds, GAM, ECA, PrintLR()\n\n# Learning Rate Schedule\nlrfn = build_lrfn()\nlr_schedule = LearningRateScheduler(lrfn, verbose=True)\n\n# Base Callbacks\nbase_cbs = [\n    EarlyStopping(patience=10, monitor='val_loss', restore_best_weights=True),\n    lr_schedule,\n    PrintLR()\n]\n\n# Convert tf.data.Dataset to numpy arrays\ndef dataset_to_numpy(ds):\n    data = list(ds.unbatch().as_numpy_iterator())\n    images = np.array([x[0] for x in data])\n    labels = np.array([x[1] for x in data])\n    return images, labels\n\nimages, labels = dataset_to_numpy(train_ds)\nlabel_indices = np.argmax(labels, axis=1)\n\n# Trackers\nbest_model = {\"fold\": None, \"train_accuracy\": 0, \"val_accuracy\": 0, \"test_accuracy\": 0, \"model\": None}\naccuracies = []\nhistory_storage = defaultdict(list)\n\n# Stratified K-Fold\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(images, label_indices)):\n    print(f\"\\nüìÇ Fold {fold + 1}\")\n\n    # Split data\n    X_train, X_val = images[train_idx], images[val_idx]\n    y_train, y_val = labels[train_idx], labels[val_idx]\n\n    train_fold_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(8).prefetch(tf.data.AUTOTUNE)\n    val_fold_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(8).prefetch(tf.data.AUTOTUNE)\n\n    # Unique checkpoint per fold\n    checkpoint_path = f\"best_attention_fold{fold+1}.weights.h5\"\n    if os.path.exists(checkpoint_path):\n        os.remove(checkpoint_path)\n\n    model_checkpoint = ModelCheckpoint(\n        checkpoint_path,\n        monitor='val_categorical_accuracy',\n        save_best_only=True,\n        mode='max',\n        save_weights_only=True\n    )\n\n    # üîÅ Build and compile attention-based model\n    model = create_model()\n    model.compile(\n        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05),\n        optimizer=tf.keras.optimizers.Adam(BASE_LR),\n        metrics=[\"categorical_accuracy\"]\n    )\n\n    # Train\n    history = model.fit(\n        train_fold_ds,\n        validation_data=val_fold_ds,\n        epochs=35,\n        callbacks=base_cbs + [model_checkpoint],\n        class_weight=class_weights,\n        verbose=1\n    )\n\n    # Load best weights\n    model.load_weights(checkpoint_path)\n\n    # Store history\n    for metric in history.history:\n        history_storage[metric].append(history.history[metric])\n\n    # Evaluate\n    test_acc = model.evaluate(test_ds, verbose=0)[1]\n    accuracies.append(test_acc)\n\n    if test_acc > best_model[\"test_accuracy\"]:\n        best_model = {\n            \"fold\": fold + 1,\n            \"train_accuracy\": max(history.history['categorical_accuracy']),\n            \"val_accuracy\": max(history.history['val_categorical_accuracy']),\n            \"test_accuracy\": test_acc,\n            \"model\": model\n        }\n\n    K.clear_session()\n    gc.collect()\n\n    print(f\"\\n‚úÖ Fold {fold + 1} Results:\")\n    print(f\"Test Accuracy: {test_acc:.4f}\")\n\n# Final Summary\nprint(\"\\nüèÜ Best Fold:\", best_model[\"fold\"])\nprint(f\"Train Accuracy: {best_model['train_accuracy']:.4f}\")\nprint(f\"Validation Accuracy: {best_model['val_accuracy']:.4f}\")\nprint(f\"Test Accuracy: {best_model['test_accuracy']:.4f}\")\nprint(f\"Mean Accuracy: {np.mean(accuracies):.4f} ¬± {np.std(accuracies):.4f}\")\n\n# Save best model weights\nbest_model[\"model\"].save_weights(\"best_attention_model.weights.h5\")\n\n# Plotting Function\nfrom tensorflow.keras.utils import pad_sequences\n\ndef plot_combined_histories(history_storage):\n    plt.figure(figsize=(15, 10))\n    metrics = ['loss', 'categorical_accuracy', 'val_loss', 'val_categorical_accuracy']\n    titles = ['Training Loss', 'Training Accuracy', 'Validation Loss', 'Validation Accuracy']\n    color = '#1f77b4'\n\n    for idx, metric in enumerate(metrics):\n        plt.subplot(2, 2, idx + 1)\n        if metric in history_storage:\n            padded = pad_sequences(history_storage[metric], padding='post', dtype='float32')\n            for h in padded:\n                plt.plot(h, color=color, alpha=0.3)\n            plt.plot(np.mean(padded, axis=0), color=color, linestyle='--')\n        plt.title(titles[idx])\n        plt.xlabel('Epochs')\n        plt.ylabel(metric.replace('_', ' ').title())\n    plt.tight_layout()\n    plt.suptitle('Training Curves Across Folds', y=1.02)\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:20:19.41913Z","iopub.execute_input":"2025-06-14T00:20:19.419523Z","iopub.status.idle":"2025-06-14T00:23:31.656552Z","shell.execute_reply.started":"2025-06-14T00:20:19.419495Z","shell.execute_reply":"2025-06-14T00:23:31.655868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_combined_histories(history_storage)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:23:31.661386Z","iopub.execute_input":"2025-06-14T00:23:31.661646Z","iopub.status.idle":"2025-06-14T00:23:32.436674Z","shell.execute_reply.started":"2025-06-14T00:23:31.661624Z","shell.execute_reply":"2025-06-14T00:23:32.435867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_accuracy_vs_val_accuracy(history_storage):\n    train_acc = history_storage['categorical_accuracy']\n    val_acc = history_storage['val_categorical_accuracy']\n\n    from tensorflow.keras.utils import pad_sequences\n    train_acc = pad_sequences(train_acc, padding='post', dtype='float32')\n    val_acc = pad_sequences(val_acc, padding='post', dtype='float32')\n\n    plt.figure(figsize=(8, 6))\n    for i in range(len(train_acc)):\n        plt.plot(train_acc[i], label=f'Train Fold {i+1}', linestyle='-')\n        plt.plot(val_acc[i], label=f'Val Fold {i+1}', linestyle='--')\n    plt.title(\"Training vs Validation Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.grid(True)\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\ndef plot_loss_vs_val_loss(history_storage):\n    train_losses = history_storage['loss']\n    val_losses = history_storage['val_loss']\n\n    from tensorflow.keras.utils import pad_sequences\n    train_losses = pad_sequences(train_losses, padding='post', dtype='float32')\n    val_losses = pad_sequences(val_losses, padding='post', dtype='float32')\n\n    plt.figure(figsize=(8, 6))\n    for i in range(len(train_losses)):\n        plt.plot(train_losses[i], label=f'Train Fold {i+1}', linestyle='-')\n        plt.plot(val_losses[i], label=f'Val Fold {i+1}', linestyle='--')\n    plt.title(\"Training vs Validation Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.grid(True)\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\ndef plot_confusion_matrix_and_report(model, test_ds, class_names):\n    # Convert dataset to numpy\n    test_data = list(test_ds.unbatch().as_numpy_iterator())\n    X_test = np.array([x[0] for x in test_data])\n    y_true_onehot = np.array([x[1] for x in test_data])\n    y_true = np.argmax(y_true_onehot, axis=1)\n\n    # Predict\n    y_pred_probs = model.predict(X_test, batch_size=8, verbose=0)\n    y_pred = np.argmax(y_pred_probs, axis=1)\n\n    # Classification Report\n    print(\"\\nüìã Classification Report:\\n\")\n    print(classification_report(y_true, y_pred, target_names=class_names))\n\n    # Confusion Matrix\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title('Confusion Matrix')\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:25:45.639426Z","iopub.execute_input":"2025-06-14T00:25:45.639771Z","iopub.status.idle":"2025-06-14T00:25:45.652059Z","shell.execute_reply.started":"2025-06-14T00:25:45.639745Z","shell.execute_reply":"2025-06-14T00:25:45.651247Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_accuracy_vs_val_accuracy(history_storage)\nplot_loss_vs_val_loss(history_storage)\n\n# For classification report and confusion matrix\nclass_names = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']  # modify if needed\nplot_confusion_matrix_and_report(best_model[\"model\"], test_ds, class_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:25:49.802068Z","iopub.execute_input":"2025-06-14T00:25:49.802739Z","iopub.status.idle":"2025-06-14T00:25:55.824617Z","shell.execute_reply.started":"2025-06-14T00:25:49.80271Z","shell.execute_reply":"2025-06-14T00:25:55.823597Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for layer in model.layers:\n    print(layer.name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T00:23:40.854708Z","iopub.execute_input":"2025-06-14T00:23:40.854958Z","iopub.status.idle":"2025-06-14T00:23:40.922356Z","shell.execute_reply.started":"2025-06-14T00:23:40.854938Z","shell.execute_reply":"2025-06-14T00:23:40.921663Z"}},"outputs":[],"execution_count":null}]}