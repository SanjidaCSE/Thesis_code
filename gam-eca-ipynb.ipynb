{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934},{"sourceId":6496514,"sourceType":"datasetVersion","datasetId":3754858}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense, BatchNormalization, Conv2D, DepthwiseConv2D, Add, Activation, BatchNormalization, ReLU\n\n# Allow memory growth\nos.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(\"Could not set memory growth:\", e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:19:15.176095Z","iopub.execute_input":"2025-06-09T11:19:15.176961Z","iopub.status.idle":"2025-06-09T11:19:15.182709Z","shell.execute_reply.started":"2025-06-09T11:19:15.176931Z","shell.execute_reply":"2025-06-09T11:19:15.181794Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\n\nclass GAM(tf.keras.layers.Layer):\n    def __init__(self, reduction_ratio=16):\n        super(GAM, self).__init__()\n        self.reduction_ratio = reduction_ratio\n\n    def build(self, input_shape):\n        channels = input_shape[-1]\n        self.channel_mlp = tf.keras.Sequential([\n            layers.Dense(channels // self.reduction_ratio, activation='relu'),\n            layers.Dense(channels)\n        ])\n        self.spatial_conv = tf.keras.Sequential([\n            layers.Conv2D(channels // self.reduction_ratio, 7, padding='same', activation='relu'),\n            layers.Conv2D(1, 7, padding='same', activation='sigmoid')\n        ])\n\n    def call(self, inputs):\n        ch_att = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n        ch_att = self.channel_mlp(ch_att)\n        sp_att = self.spatial_conv(inputs)\n        return inputs * ch_att * sp_att\n\nclass ECA(tf.keras.layers.Layer):\n    def __init__(self, gamma=2, b=1):\n        super(ECA, self).__init__()\n        self.gamma = gamma\n        self.b = b\n\n    def build(self, input_shape):\n        channels = input_shape[-1]\n        k = int(abs((tf.math.log(tf.cast(channels, tf.float32)) / tf.math.log(2.0) + self.b) / self.gamma))\n        self.kernel_size = k if k % 2 else k + 1\n        self.conv = layers.Conv1D(1, kernel_size=self.kernel_size, padding='same', use_bias=False)\n\n    def call(self, inputs):\n        x = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n        x = tf.squeeze(x, axis=[1, 2])\n        x = tf.expand_dims(x, axis=-1)\n        x = self.conv(x)\n        x = tf.sigmoid(x)\n        x = tf.reshape(x, [-1, 1, 1, inputs.shape[-1]])\n        return inputs * x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:19:15.202329Z","iopub.execute_input":"2025-06-09T11:19:15.20265Z","iopub.status.idle":"2025-06-09T11:19:15.213086Z","shell.execute_reply.started":"2025-06-09T11:19:15.202623Z","shell.execute_reply":"2025-06-09T11:19:15.212253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.layers import (Conv2D, DepthwiseConv2D, BatchNormalization, ReLU,\n                                     Add, Input, GlobalAveragePooling2D, Dropout, Dense)\n\ndef fused_mbconv(x, out_filters, expansion, stride):\n    in_filters = x.shape[-1]\n    hidden_dim = in_filters * expansion\n\n    x_input = x\n    x = Conv2D(hidden_dim, 3, strides=stride, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(out_filters, 1, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x = GAM()(x)\n\n    if stride == 1 and in_filters == out_filters:\n        x = Add()([x_input, x])\n    return x\n\ndef mbconv(x, out_filters, expansion, stride):\n    in_filters = x.shape[-1]\n    hidden_dim = in_filters * expansion\n\n    x_input = x\n    x = Conv2D(hidden_dim, 1, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = DepthwiseConv2D(3, strides=stride, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(out_filters, 1, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x = ECA()(x)\n\n    if stride == 1 and in_filters == out_filters:\n        x = Add()([x_input, x])\n    return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:19:15.230589Z","iopub.execute_input":"2025-06-09T11:19:15.231319Z","iopub.status.idle":"2025-06-09T11:19:15.238637Z","shell.execute_reply.started":"2025-06-09T11:19:15.231292Z","shell.execute_reply":"2025-06-09T11:19:15.237749Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_paper_lowflops_model(input_shape=(224, 224, 3), num_classes=4):\n    inputs = Input(shape=input_shape)\n    x = Conv2D(32, 3, strides=2, padding='same')(inputs)  # Smaller stem\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    # Updated reduced-width blocks\n    blocks = [\n        (1, 16, 2, 1, 'fused'),    # lower out_channels\n        (2, 24, 3, 2, 'fused'),\n        (2, 32, 3, 2, 'fused'),\n        (3, 64, 4, 2, 'mbconv'),\n        (3, 96, 6, 1, 'mbconv'),\n        (4, 160, 12, 2, 'mbconv'),\n        (4, 128, 2, 1, 'mbconv')\n    ]\n\n    for expansion, out_filters, repeats, stride, block_type in blocks:\n        for i in range(repeats):\n            s = stride if i == 0 else 1\n            if block_type == 'fused':\n                x = fused_mbconv(x, out_filters, expansion, s)\n            else:\n                x = mbconv(x, out_filters, expansion, s)\n\n    x = Conv2D(128, 1, padding='same')(x)  # Final bottleneck layer much smaller\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.3)(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    outputs = Dense(num_classes, activation='softmax')(x)\n\n    return tf.keras.Model(inputs, outputs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:19:15.250292Z","iopub.execute_input":"2025-06-09T11:19:15.250583Z","iopub.status.idle":"2025-06-09T11:19:15.258216Z","shell.execute_reply.started":"2025-06-09T11:19:15.25056Z","shell.execute_reply":"2025-06-09T11:19:15.25743Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n\ndef get_flops(model, batch_size=1):\n    # Build the model if not already built\n    if not model.built:\n        model.build(input_shape=(batch_size, *model.input_shape[1:]))\n\n    # Get concrete function\n    concrete_func = tf.function(model).get_concrete_function(\n        tf.TensorSpec([batch_size, *model.input_shape[1:]], model.inputs[0].dtype)\n    )\n\n    # Convert to frozen concrete function\n    frozen_func = convert_variables_to_constants_v2(concrete_func)\n\n    # Use TF1 profiler API to calculate FLOPs\n    run_meta = tf.compat.v1.RunMetadata()\n    opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n\n    flops = tf.compat.v1.profiler.profile(\n        graph=frozen_func.graph,\n        run_meta=run_meta,\n        cmd='op',\n        options=opts\n    )\n\n    return flops.total_float_ops if flops is not None else 0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:19:15.263631Z","iopub.execute_input":"2025-06-09T11:19:15.263939Z","iopub.status.idle":"2025-06-09T11:19:15.272124Z","shell.execute_reply.started":"2025-06-09T11:19:15.263917Z","shell.execute_reply":"2025-06-09T11:19:15.271347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_paper_lowflops_model()\nflops = get_flops(model, batch_size=1)\nparams = model.count_params()\n\nprint(\"=============================================\")\nprint(f\"üßÆ FLOPs: {flops / 1e9:.03f} GFLOPs\")\nprint(f\"üî¢ Parameters: {params:,}\")\nprint(\"=============================================\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:19:15.294934Z","iopub.execute_input":"2025-06-09T11:19:15.295221Z","iopub.status.idle":"2025-06-09T11:19:21.959886Z","shell.execute_reply.started":"2025-06-09T11:19:15.2952Z","shell.execute_reply":"2025-06-09T11:19:21.959025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def cbam_block(inputs, reduction_ratio=8):\n    channel = inputs.shape[-1]\n\n    # Channel Attention\n    avg_pool = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n    max_pool = tf.reduce_max(inputs, axis=[1, 2], keepdims=True)\n\n    dense1 = tf.keras.layers.Dense(channel // reduction_ratio, activation='relu', use_bias=False)\n    dense2 = tf.keras.layers.Dense(channel, use_bias=False)\n\n    avg_out = dense2(dense1(avg_pool))\n    max_out = dense2(dense1(max_pool))\n    scale = tf.keras.activations.sigmoid(avg_out + max_out)\n    x = tf.multiply(inputs, scale)\n\n    # Spatial Attention\n    avg_pool_spatial = tf.reduce_mean(x, axis=-1, keepdims=True)\n    max_pool_spatial = tf.reduce_max(x, axis=-1, keepdims=True)\n    concat = tf.concat([avg_pool_spatial, max_pool_spatial], axis=-1)\n    spatial = tf.keras.layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')(concat)\n    return tf.multiply(x, spatial)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:19:26.262043Z","iopub.execute_input":"2025-06-09T11:19:26.262513Z","iopub.status.idle":"2025-06-09T11:19:26.27193Z","shell.execute_reply.started":"2025-06-09T11:19:26.262473Z","shell.execute_reply":"2025-06-09T11:19:26.271025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fused_mbconv(x, out_filters, expansion, stride):\n    input_channels = x.shape[-1]\n    x = tf.keras.layers.Conv2D(input_channels * expansion, 3, strides=stride, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Conv2D(out_filters, 1, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = cbam_block(x)\n    return x\ndef mbconv(x, out_filters, expansion, stride):\n    input_channels = x.shape[-1]\n    \n    # Expansion phase\n    expanded = tf.keras.layers.Conv2D(input_channels * expansion, 1, padding='same')(x)\n    expanded = tf.keras.layers.BatchNormalization()(expanded)\n    expanded = tf.keras.layers.ReLU()(expanded)\n\n    # Depthwise convolution\n    depthwise = tf.keras.layers.DepthwiseConv2D(3, strides=stride, padding='same')(expanded)\n    depthwise = tf.keras.layers.BatchNormalization()(depthwise)\n    depthwise = tf.keras.layers.ReLU()(depthwise)\n\n    # Projection\n    projected = tf.keras.layers.Conv2D(out_filters, 1, padding='same')(depthwise)\n    projected = tf.keras.layers.BatchNormalization()(projected)\n    projected = cbam_block(projected)\n\n    # Residual connection\n    if stride == 1 and input_channels == out_filters:\n        return tf.keras.layers.Add()([x, projected])\n    else:\n        return projected\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:19:26.273083Z","iopub.execute_input":"2025-06-09T11:19:26.273379Z","iopub.status.idle":"2025-06-09T11:19:26.288065Z","shell.execute_reply.started":"2025-06-09T11:19:26.273353Z","shell.execute_reply":"2025-06-09T11:19:26.287188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetV2S\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout\n\ndef build_cbam_efficientnetv2s(input_shape=(224, 224, 3), num_classes=4):\n    inputs = Input(shape=input_shape)\n    x = Conv2D(32, 3, strides=2, padding='same')(inputs)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    blocks = [\n        (1, 16, 2, 1, 'fused'),\n        (2, 24, 3, 2, 'fused'),\n        (2, 32, 3, 2, 'fused'),\n        (3, 64, 4, 2, 'mbconv'),\n        (3, 96, 6, 1, 'mbconv'),\n        (4, 160, 12, 2, 'mbconv'),\n        (4, 128, 2, 1, 'mbconv')\n    ]\n\n    for expansion, out_filters, repeats, stride, block_type in blocks:\n        for i in range(repeats):\n            s = stride if i == 0 else 1\n            if block_type == 'fused':\n                x = fused_mbconv(x, out_filters, expansion, s)\n            else:\n                x = mbconv(x, out_filters, expansion, s)\n\n    x = Conv2D(128, 1, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.3)(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    outputs = Dense(num_classes, activation='softmax')(x)\n\n    return Model(inputs, outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:19:26.290071Z","iopub.execute_input":"2025-06-09T11:19:26.290324Z","iopub.status.idle":"2025-06-09T11:19:26.304847Z","shell.execute_reply.started":"2025-06-09T11:19:26.290303Z","shell.execute_reply":"2025-06-09T11:19:26.304047Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_cbam_efficientnetv2s()\nflops = get_flops(model, batch_size=1)\nparams = model.count_params()\n\nprint(\"=============================================\")\nprint(f\"üßÆ FLOPs: {flops / 1e9:.03f} GFLOPs\")\nprint(f\"üî¢ Parameters: {params:,}\")\nprint(\"=============================================\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:22:21.275545Z","iopub.execute_input":"2025-06-09T11:22:21.275884Z","iopub.status.idle":"2025-06-09T11:22:30.236935Z","shell.execute_reply.started":"2025-06-09T11:22:21.275858Z","shell.execute_reply":"2025-06-09T11:22:30.236042Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! pip install imutils\n!pip install tensorflow\n\nimport tensorflow as tf\nfrom sklearn.utils.class_weight import compute_class_weight\nimport matplotlib.pyplot as plt\nimport imutils\nimport pathlib\nimport time\nimport PIL as pil\nimport shutil\nfrom tqdm import tqdm\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport gc\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport itertools\nimport joblib\n\n\n\nIMAGE_SIZE = (224, 224)\nBASE_LR = 2e-5\nEPOCH = 20\nBATCH_SIZE = 8","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:24:26.891502Z","iopub.execute_input":"2025-06-09T11:24:26.89218Z","iopub.status.idle":"2025-06-09T11:24:43.82603Z","shell.execute_reply.started":"2025-06-09T11:24:26.892129Z","shell.execute_reply":"2025-06-09T11:24:43.824855Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install tensorflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:25:05.554033Z","iopub.execute_input":"2025-06-09T11:25:05.554415Z","iopub.status.idle":"2025-06-09T11:25:14.012555Z","shell.execute_reply.started":"2025-06-09T11:25:05.554383Z","shell.execute_reply":"2025-06-09T11:25:14.011643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def crop_img(img, image_size=(224, 224)):\n    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n\n    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n    thresh = cv2.erode(thresh, None, iterations=2)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    cnts = imutils.grab_contours(cnts)\n    \n    if len(cnts) == 0:\n        print(\"Warning: No contours found, returning resized original image.\")\n        return cv2.resize(img, image_size, interpolation=cv2.INTER_CUBIC)\n    \n    c = max(cnts, key=cv2.contourArea)\n\n    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n    extRight = tuple(c[c[:, :, 0].argmax()][0])\n    extTop = tuple(c[c[:, :, 1].argmin()][0])\n    extBot = tuple(c[c[:, :, 1].argmax()][0])\n\n    ADD_PIXELS = 0\n    new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n    new_img = cv2.resize(new_img, image_size, interpolation=cv2.INTER_CUBIC)\n    return new_img\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:25:18.462443Z","iopub.execute_input":"2025-06-09T11:25:18.462803Z","iopub.status.idle":"2025-06-09T11:25:18.472056Z","shell.execute_reply.started":"2025-06-09T11:25:18.462773Z","shell.execute_reply":"2025-06-09T11:25:18.470992Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def image_preprocessing(source_dir, saved_root_dir, image_size=(224, 224), channels=3):\n    if not os.path.exists(source_dir):\n        raise Exception(f\"Source directory: {source_dir} does not exist\")\n    if not os.path.isdir(source_dir):\n        raise Exception(f\"Source path: {source_dir} is not a directory\")\n\n    if not os.path.exists(saved_root_dir):\n        os.makedirs(saved_root_dir)\n        \n    source_dir_path = pathlib.Path(source_dir)\n    \n    for p in tqdm(source_dir_path.iterdir(), desc=\"Processing folders\"):\n        dir_name = str(p).split(\"/\")[-1]\n        for fp in p.iterdir():\n            filename = str(fp).split(\"/\")[-1]\n\n            img = tf.io.read_file(str(fp))\n            img = tf.image.decode_jpeg(img, channels=channels)\n            img = crop_img(img.numpy(), image_size)\n            # img = cv2.imread(str(fp))\n            # if img is None:\n            #     continue\n\n            # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n            # # === Apply CLAHE enhancement ===\n            # gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n            # clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            # enhanced_gray = clahe.apply(gray)\n            # img = cv2.cvtColor(enhanced_gray, cv2.COLOR_GRAY2RGB)\n\n            # # === Apply cropping ===\n            # img = crop_img(img, image_size)\n\n            img = pil.Image.fromarray(img)\n\n            saved_dist_dir = os.path.join(saved_root_dir, dir_name)\n            if not os.path.exists(saved_dist_dir):\n                os.makedirs(saved_dist_dir)\n\n            img_dist_path = os.path.join(saved_dist_dir, filename)\n            img.save(img_dist_path)\n    print(f\"\\n‚úÖ All images processed and saved to: {saved_root_dir}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:25:25.52734Z","iopub.execute_input":"2025-06-09T11:25:25.527672Z","iopub.status.idle":"2025-06-09T11:25:25.535608Z","shell.execute_reply.started":"2025-06-09T11:25:25.527645Z","shell.execute_reply":"2025-06-09T11:25:25.534689Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_preprocessing(\n    \"/kaggle/input/brain-tumor-mri-dataset/Training\",\n    \"/kaggle/working/processed/Training\",\n    image_size=IMAGE_SIZE\n)\n\nimage_preprocessing(\n    \"/kaggle/input/brain-tumor-mri-dataset/Testing\",\n    \"/kaggle/working/processed/Testing\",\n    image_size=IMAGE_SIZE\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:25:36.032604Z","iopub.execute_input":"2025-06-09T11:25:36.033363Z","iopub.status.idle":"2025-06-09T11:26:13.632442Z","shell.execute_reply.started":"2025-06-09T11:25:36.03333Z","shell.execute_reply":"2025-06-09T11:26:13.631462Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Datasets","metadata":{"id":"YuJXo3b-f7PX"}},{"cell_type":"code","source":"root_dir_path = \"/kaggle/working/brain-tumor-mri-dataset\"","metadata":{"id":"nLLkxrD0ivtJ","trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:26:17.591923Z","iopub.execute_input":"2025-06-09T11:26:17.592298Z","iopub.status.idle":"2025-06-09T11:26:17.596467Z","shell.execute_reply.started":"2025-06-09T11:26:17.592272Z","shell.execute_reply":"2025-06-09T11:26:17.595588Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = tf.keras.utils.image_dataset_from_directory(\n    \"/kaggle/working/processed/Training\",\n    label_mode=\"categorical\",\n    batch_size=BATCH_SIZE,\n    image_size=IMAGE_SIZE,\n    seed=42\n)\n\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n    \"/kaggle/working/processed/Testing\",\n    label_mode=\"categorical\",\n    batch_size=BATCH_SIZE,\n    image_size=IMAGE_SIZE,\n    shuffle=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:26:22.513918Z","iopub.execute_input":"2025-06-09T11:26:22.514303Z","iopub.status.idle":"2025-06-09T11:26:22.908837Z","shell.execute_reply.started":"2025-06-09T11:26:22.514278Z","shell.execute_reply":"2025-06-09T11:26:22.907898Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint(\"Class names:\", class_names)\n\ncls_to_id = {c: i for i, c in enumerate(class_names)}\nid_to_cls = {i: c for i, c in enumerate(class_names)}\nprint(\"cls_to_id:\", cls_to_id)\nprint(\"id_to_cls:\", id_to_cls)","metadata":{"id":"8Q3yArLCf7Pe","outputId":"6a76410d-f086-4531-b6cc-6599f0fb2512","trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:26:32.95025Z","iopub.execute_input":"2025-06-09T11:26:32.950572Z","iopub.status.idle":"2025-06-09T11:26:32.95624Z","shell.execute_reply.started":"2025-06-09T11:26:32.950547Z","shell.execute_reply":"2025-06-09T11:26:32.955429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ‚úÖ Apply real-time data augmentation to training set only\ndata_augmentation = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(\"horizontal\"),\n    tf.keras.layers.RandomRotation(0.1),\n    tf.keras.layers.RandomZoom(0.1),\n])\n\ntrain_ds = train_ds.map(lambda x, y: (data_augmentation(x), y))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:26:39.19206Z","iopub.execute_input":"2025-06-09T11:26:39.192851Z","iopub.status.idle":"2025-06-09T11:26:39.489949Z","shell.execute_reply.started":"2025-06-09T11:26:39.192823Z","shell.execute_reply":"2025-06-09T11:26:39.489026Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"class_to_id.txt\", \"w\") as f:\n    for k, v in cls_to_id.items():\n        f.write(f\"{k}\\t{v}\\n\")\n\nwith open(\"id_to_class.txt\", \"w\") as f:\n    for k, v in id_to_cls.items():\n        f.write(f\"{k}\\t{v}\\n\")","metadata":{"id":"uPjSeagdf7Pf","trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:26:45.341655Z","iopub.execute_input":"2025-06-09T11:26:45.342521Z","iopub.status.idle":"2025-06-09T11:26:45.347746Z","shell.execute_reply.started":"2025-06-09T11:26:45.342491Z","shell.execute_reply":"2025-06-09T11:26:45.347016Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"class_to_id.txt\", \"r\") as f:\n    for line in f.readlines():\n        cls, label = line.replace(\"\\n\",\"\").split(\"\\t\")\n        print(cls, int(label))\nprint(\"\\n\")\nwith open(\"id_to_class.txt\", \"r\") as f:\n    for line in f.readlines():\n        label, cls = line.replace(\"\\n\",\"\").split(\"\\t\")\n        print(int(label), cls)","metadata":{"id":"XLvvdUm6f7Pf","outputId":"b2aa2166-813d-42a6-fb31-2d166c69afbf","trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:26:53.095602Z","iopub.execute_input":"2025-06-09T11:26:53.095921Z","iopub.status.idle":"2025-06-09T11:26:53.102377Z","shell.execute_reply.started":"2025-06-09T11:26:53.095895Z","shell.execute_reply":"2025-06-09T11:26:53.101556Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def class_weight_from_one_hot(ds):\n    class_labels = []\n    if ds.__class__.__name__ == \"_BatchDataset\":\n        ds = ds.unbatch()\n\n    for _, onehot in ds:\n        label = tf.argmax(onehot).numpy()\n        if label.shape == ():  # scalar\n            class_labels.append(label.item())\n        else:  # batch\n            class_labels.extend([l.item() for l in label])\n\n    unique_classes = np.unique(class_labels)\n    class_weights = compute_class_weight(class_weight=\"balanced\", \n                                         classes=unique_classes,\n                                         y=class_labels)\n    return {i: w for i, w in enumerate(class_weights)}\n\n\n    \nclass_weights = class_weight_from_one_hot(train_ds)\nprint(class_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:27:03.03859Z","iopub.execute_input":"2025-06-09T11:27:03.039178Z","iopub.status.idle":"2025-06-09T11:27:54.966014Z","shell.execute_reply.started":"2025-06-09T11:27:03.039149Z","shell.execute_reply":"2025-06-09T11:27:54.965125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for images, labels in train_ds.take(1):\n    image, label = images[0], labels[0]\n    plt.figure()\n    plt.imshow(tf.cast(image, tf.uint8))\n    plt.title(class_names[tf.argmax(label).numpy()])\n    plt.axis(\"off\")\n    plt.show()\n","metadata":{"id":"f2EnMhWWf7Pf","outputId":"b33194ba-2d4f-4efa-ce72-84677d5d64ba","trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:28:19.906514Z","iopub.execute_input":"2025-06-09T11:28:19.906837Z","iopub.status.idle":"2025-06-09T11:28:20.33015Z","shell.execute_reply.started":"2025-06-09T11:28:19.90681Z","shell.execute_reply":"2025-06-09T11:28:20.329302Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{"id":"8XEQ_expf7Ph"}},{"cell_type":"code","source":"class PrintLR(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        lr = self.model.optimizer.lr\n        if hasattr(lr, 'numpy'):\n            print(f\"üîÅ Epoch {epoch+1}: Learning rate = {lr.numpy():.6f}\")\n        else:\n            print(f\"üîÅ Epoch {epoch+1}: Learning rate = {tf.keras.backend.get_value(lr):.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:28:29.013957Z","iopub.execute_input":"2025-06-09T11:28:29.014321Z","iopub.status.idle":"2025-06-09T11:28:29.019896Z","shell.execute_reply.started":"2025-06-09T11:28:29.014294Z","shell.execute_reply":"2025-06-09T11:28:29.019029Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_lrfn(\n    lr_start=1e-4,\n    lr_max=5e-4,\n    lr_min=1e-6,\n    lr_rampup_epochs=5,\n    lr_sustain_epochs=5,\n    lr_exp_decay=0.8\n):\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:28:36.380232Z","iopub.execute_input":"2025-06-09T11:28:36.380577Z","iopub.status.idle":"2025-06-09T11:28:36.386108Z","shell.execute_reply.started":"2025-06-09T11:28:36.38055Z","shell.execute_reply":"2025-06-09T11:28:36.385034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def build_lrfn(lr_start=2e-5, lr_max=1e-3,\n#                lr_min=1e-6, lr_rampup_epochs=8,\n#                lr_sustain_epochs=0, lr_exp_decay=0.8):\n\n#     def lrfn(epoch):\n#         if epoch < lr_rampup_epochs:\n#             lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n#         elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n#             lr = lr_max\n#         else:\n#             lr = (lr_max - lr_min) * \\\n#                  lr_exp_decay ** (epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n#         return lr\n\n#     return lrfn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:19:45.534564Z","iopub.status.idle":"2025-06-09T11:19:45.534954Z","shell.execute_reply.started":"2025-06-09T11:19:45.534752Z","shell.execute_reply":"2025-06-09T11:19:45.534771Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\n# Remove previous best model file if it exists\nif os.path.exists(\"best_initial_model.keras\"):\n    os.remove(\"best_initial_model.keras\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:28:43.124472Z","iopub.execute_input":"2025-06-09T11:28:43.124804Z","iopub.status.idle":"2025-06-09T11:28:43.129221Z","shell.execute_reply.started":"2025-06-09T11:28:43.12478Z","shell.execute_reply":"2025-06-09T11:28:43.128318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nimport gc\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nfrom collections import defaultdict\n\n# === Assumes the following are defined ===\n# BASE_LR, build_lrfn(), build_paper_lowflops_model(), class_weights, train_ds, test_ds\n\n# Learning Rate Schedule\nlrfn = build_lrfn()\nlr_schedule = LearningRateScheduler(lrfn, verbose=True)\n\n# Base Callbacks\nbase_cbs = [\n    EarlyStopping(patience=10, monitor='val_loss', restore_best_weights=True),\n    lr_schedule,\n    PrintLR()\n    # ReduceLROnPlateau(patience=5, factor=0.5),\n    # lr_schedule\n]\n\n# Convert tf.data.Dataset to numpy arrays\ndef dataset_to_numpy(ds):\n    data = list(ds.unbatch().as_numpy_iterator())\n    images = np.array([x[0] for x in data])\n    labels = np.array([x[1] for x in data])\n    return images, labels\n\nimages, labels = dataset_to_numpy(train_ds)\nlabel_indices = np.argmax(labels, axis=1)\n\n# Trackers\nbest_model = {\"fold\": None, \"train_accuracy\": 0, \"val_accuracy\": 0, \"test_accuracy\": 0, \"model\": None}\naccuracies = []\nhistory_storage = defaultdict(list)\n\n# Stratified K-Fold\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(images, label_indices)):\n    print(f\"\\nüìÇ Fold {fold + 1}\")\n\n    # Split data\n    X_train, X_val = images[train_idx], images[val_idx]\n    y_train, y_val = labels[train_idx], labels[val_idx]\n\n    train_fold_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(8).prefetch(tf.data.AUTOTUNE)\n    val_fold_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(8).prefetch(tf.data.AUTOTUNE)\n\n    # Unique checkpoint per fold\n    checkpoint_path = f\"best_lowflops_fold{fold+1}.weights.h5\"\n    if os.path.exists(checkpoint_path):\n        os.remove(checkpoint_path)\n\n    model_checkpoint = ModelCheckpoint(\n        checkpoint_path,\n        monitor='val_categorical_accuracy',\n        save_best_only=True,\n        mode='max',\n        save_weights_only=True  # ‚úÖ Prevent internal name conflict\n    )\n\n    # Build and compile model\n    model = build_paper_lowflops_model()\n    model.compile(\n        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05),\n        optimizer=tf.keras.optimizers.Adam(BASE_LR),\n        metrics=[\"categorical_accuracy\"]\n    )\n\n    # Train\n    history = model.fit(\n        train_fold_ds,\n        validation_data=val_fold_ds,\n        epochs=40,\n        callbacks=base_cbs + [model_checkpoint],\n        class_weight=class_weights,\n        verbose=1\n    )\n        # Load best weights for this fold\n    model.load_weights(checkpoint_path)\n\n    # Store history\n    for metric in history.history:\n        history_storage[metric].append(history.history[metric])\n\n    # Evaluate\n    test_acc = model.evaluate(test_ds, verbose=0)[1]\n    accuracies.append(test_acc)\n\n    if test_acc > best_model[\"test_accuracy\"]:\n        best_model = {\n            \"fold\": fold + 1,\n            \"train_accuracy\": max(history.history['categorical_accuracy']),\n            \"val_accuracy\": max(history.history['val_categorical_accuracy']),\n            \"test_accuracy\": test_acc,\n            \"model\": model\n        }\n\n    K.clear_session()\n    gc.collect()\n\n    print(f\"\\n‚úÖ Fold {fold + 1} Results:\")\n    print(f\"Test Accuracy: {test_acc:.4f}\")\n\n# Final Summary\nprint(\"\\nüèÜ Best Fold:\", best_model[\"fold\"])\nprint(f\"Train Accuracy: {best_model['train_accuracy']:.4f}\")\nprint(f\"Validation Accuracy: {best_model['val_accuracy']:.4f}\")\nprint(f\"Test Accuracy: {best_model['test_accuracy']:.4f}\")\nprint(f\"Mean Accuracy: {np.mean(accuracies):.4f} ¬± {np.std(accuracies):.4f}\")\n\n# Save best model (weights only)\nbest_model[\"model\"].save_weights(\"best_lowflops_model.weights.h5\")\n\n# Plotting Functions\nfrom tensorflow.keras.utils import pad_sequences\n\ndef plot_combined_histories(history_storage):\n    plt.figure(figsize=(15, 10))\n    metrics = ['loss', 'categorical_accuracy', 'val_loss', 'val_categorical_accuracy']\n    titles = ['Training Loss', 'Training Accuracy', 'Validation Loss', 'Validation Accuracy']\n    color = '#1f77b4'\n\n    for idx, metric in enumerate(metrics):\n        plt.subplot(2, 2, idx + 1)\n        if metric in history_storage:\n            padded = pad_sequences(history_storage[metric], padding='post', dtype='float32')\n            for h in padded:\n                plt.plot(h, color=color, alpha=0.3)\n            plt.plot(np.mean(padded, axis=0), color=color, linestyle='--')\n        plt.title(titles[idx])\n        plt.xlabel('Epochs')\n        plt.ylabel(metric.replace('_', ' ').title())\n    plt.tight_layout()\n    plt.suptitle('Training Curves Across Folds', y=1.02)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T11:28:51.271479Z","iopub.execute_input":"2025-06-09T11:28:51.271808Z","iopub.status.idle":"2025-06-09T14:49:28.563101Z","shell.execute_reply.started":"2025-06-09T11:28:51.271782Z","shell.execute_reply":"2025-06-09T14:49:28.562373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_model_metrics(model_key, label, history_storage):\n    \"\"\"Plot training vs validation metrics for a specific model\"\"\"\n    \n    metrics_to_plot = [\n        ('loss', 'val_loss'),\n        ('categorical_accuracy', 'val_categorical_accuracy')\n    ]\n    \n    for train_metric, val_metric in metrics_to_plot:\n        if train_metric in history_storage[model_key] and val_metric in history_storage[model_key]:\n            train_histories = history_storage[model_key][train_metric]\n            val_histories = history_storage[model_key][val_metric]\n\n            train_mean = np.mean(train_histories, axis=0)\n            train_std = np.std(train_histories, axis=0)\n\n            val_mean = np.mean(val_histories, axis=0)\n            val_std = np.std(val_histories, axis=0)\n\n            # Print values\n            print(f\"\\nüìä {label} - {train_metric.replace('_', ' ').title()} vs {val_metric.replace('_', ' ').title()}:\")\n            for i, (tr_m, tr_s, vl_m, vl_s) in enumerate(zip(train_mean, train_std, val_mean, val_std)):\n                print(f\"Epoch {i+1}: Train = {tr_m:.4f} ¬± {tr_s:.4f}, Val = {vl_m:.4f} ¬± {vl_s:.4f}\")\n\n            # Plotting\n            plt.figure(figsize=(8, 5))\n            epochs = range(len(train_mean))\n            plt.plot(epochs, train_mean, label=f\"Train {train_metric.replace('_', ' ').title()}\")\n            plt.fill_between(epochs, train_mean - train_std, train_mean + train_std, alpha=0.2)\n\n            plt.plot(epochs, val_mean, label=f\"Val {val_metric.replace('_', ' ').title()}\")\n            plt.fill_between(epochs, val_mean - val_std, val_mean + val_std, alpha=0.2)\n\n            plt.title(f\"{label} - {train_metric.replace('_', ' ').title()} vs {val_metric.replace('_', ' ').title()}\")\n            plt.xlabel(\"Epochs\")\n            plt.ylabel(train_metric.replace(\"_\", \" \").title())\n            plt.legend()\n            plt.grid(True)\n            plt.tight_layout()\n            plt.show()\n\n# Mapping of model types\nmodel_name_map = {\n    \"attention\": \"Attention Model\",\n    \"baseline\": \"Baseline Model\"\n}\n\n# Plot per model\nfor model_key, label in model_name_map.items():\n    plot_model_metrics(model_key, label, history_storage)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:59:11.465204Z","iopub.execute_input":"2025-06-09T14:59:11.465571Z","iopub.status.idle":"2025-06-09T14:59:11.476308Z","shell.execute_reply.started":"2025-06-09T14:59:11.465543Z","shell.execute_reply":"2025-06-09T14:59:11.475355Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# ‚úÖ Get true labels from test_ds\ny_true = np.concatenate([y.numpy() for _, y in test_ds], axis=0)\ny_true = np.argmax(y_true, axis=1)\n\n# ‚úÖ Get predictions from the best model\ny_pred_probs = best_model[\"model\"].predict(test_ds, verbose=0)\ny_pred = np.argmax(y_pred_probs, axis=1)\n\n# ‚úÖ Define class names\nclass_names = ['glioma', 'meningioma', 'no_tumor', 'pituitary']\n\n# ‚úÖ Print classification report\nreport = classification_report(\n    y_true,\n    y_pred,\n    target_names=class_names,\n    digits=4\n)\n\nprint(\"üìä Classification Report:\\n\")\nprint(report)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:59:16.255543Z","iopub.execute_input":"2025-06-09T14:59:16.256331Z","iopub.status.idle":"2025-06-09T14:59:30.040663Z","shell.execute_reply.started":"2025-06-09T14:59:16.256298Z","shell.execute_reply":"2025-06-09T14:59:30.039832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# ‚úÖ Step 1: Get true labels and predictions from test_ds\ny_true = []\ny_pred = []\n\nfor images, labels in test_ds:\n    preds = best_model[\"model\"].predict(images, verbose=0)\n    y_true.extend(np.argmax(labels.numpy(), axis=1))\n    y_pred.extend(np.argmax(preds, axis=1))\n\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\n\n# ‚úÖ Step 2: Compute the confusion matrix\nclass_names = ['glioma', 'meningioma', 'no_tumor', 'pituitary']\ncm = confusion_matrix(y_true, y_pred)\n\n# ‚úÖ Step 3: Plot using seaborn heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names)\n\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:59:48.399356Z","iopub.execute_input":"2025-06-09T14:59:48.399683Z","iopub.status.idle":"2025-06-09T15:00:10.206535Z","shell.execute_reply.started":"2025-06-09T14:59:48.399657Z","shell.execute_reply":"2025-06-09T15:00:10.20565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_best_model(history, metric='val_categorical_accuracy'):\n    val_histories = history[metric]\n    best_scores = [np.max(val_acc) for val_acc in val_histories]\n    best_fold_idx = np.argmax(best_scores)\n    return best_fold_idx\ndef plot_best_model(history, model_label, metric_key='val_categorical_accuracy'):\n    best_fold = get_best_fold_index(history, metric=metric_key)\n\n    train_acc = history['categorical_accuracy'][best_fold]\n    val_acc = history['val_categorical_accuracy'][best_fold]\n    train_loss = history['loss'][best_fold]\n    val_loss = history['val_loss'][best_fold]\n\n    print(f\"üìå Best Fold Index for {model_label}: {best_fold}\")\n\n    plt.figure(figsize=(14, 5))\n\n    # Accuracy plot\n    plt.subplot(1, 2, 1)\n    plt.plot(train_acc, label=\"Training Accuracy\")\n    plt.plot(val_acc, label=\"Validation Accuracy\")\n    plt.title(f\"{model_label} - Accuracy)\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.grid(True)\n    plt.legend()\n\n    # Loss plot\n    plt.subplot(1, 2, 2)\n    plt.plot(train_loss, label=\"Training Loss\")\n    plt.plot(val_loss, label=\"Validation Loss\")\n    plt.title(f\"{model_label} - Loss\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.grid(True)\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\nfor model_key, label in model_name_map.items():\n    print(f\"\\nüîç Analyzing best fold for: {label}\")\n    plot_best_fold(history_storage[model_key], label)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T15:00:22.493908Z","iopub.execute_input":"2025-06-09T15:00:22.494765Z","iopub.status.idle":"2025-06-09T15:00:23.095041Z","shell.execute_reply.started":"2025-06-09T15:00:22.494735Z","shell.execute_reply":"2025-06-09T15:00:23.094163Z"}},"outputs":[],"execution_count":null}]}