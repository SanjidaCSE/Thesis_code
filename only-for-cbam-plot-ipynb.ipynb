{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934},{"sourceId":6496514,"sourceType":"datasetVersion","datasetId":3754858}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense, BatchNormalization, Conv2D, DepthwiseConv2D, Add, Activation, BatchNormalization, ReLU\n\n# Allow memory growth\nos.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(\"Could not set memory growth:\", e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:25:18.353420Z","iopub.execute_input":"2025-06-14T15:25:18.353652Z","iopub.status.idle":"2025-06-14T15:25:27.562300Z","shell.execute_reply.started":"2025-06-14T15:25:18.353628Z","shell.execute_reply":"2025-06-14T15:25:27.561507Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\n\nclass GAM(tf.keras.layers.Layer):\n    def __init__(self, reduction_ratio=16):\n        super(GAM, self).__init__()\n        self.reduction_ratio = reduction_ratio\n\n    def build(self, input_shape):\n        channels = input_shape[-1]\n        self.channel_mlp = tf.keras.Sequential([\n            layers.Dense(channels // self.reduction_ratio, activation='relu'),\n            layers.Dense(channels)\n        ])\n        self.spatial_conv = tf.keras.Sequential([\n            layers.Conv2D(channels // self.reduction_ratio, 7, padding='same', activation='relu'),\n            layers.Conv2D(1, 7, padding='same', activation='sigmoid')\n        ])\n\n    def call(self, inputs):\n        ch_att = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n        ch_att = self.channel_mlp(ch_att)\n        sp_att = self.spatial_conv(inputs)\n        return inputs * ch_att * sp_att\n\nclass ECA(tf.keras.layers.Layer):\n    def __init__(self, gamma=2, b=1):\n        super(ECA, self).__init__()\n        self.gamma = gamma\n        self.b = b\n\n    def build(self, input_shape):\n        channels = input_shape[-1]\n        k = int(abs((tf.math.log(tf.cast(channels, tf.float32)) / tf.math.log(2.0) + self.b) / self.gamma))\n        self.kernel_size = k if k % 2 else k + 1\n        self.conv = layers.Conv1D(1, kernel_size=self.kernel_size, padding='same', use_bias=False)\n\n    def call(self, inputs):\n        x = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n        x = tf.squeeze(x, axis=[1, 2])\n        x = tf.expand_dims(x, axis=-1)\n        x = self.conv(x)\n        x = tf.sigmoid(x)\n        x = tf.reshape(x, [-1, 1, 1, inputs.shape[-1]])\n        return inputs * x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:25:27.566923Z","iopub.execute_input":"2025-06-14T15:25:27.567167Z","iopub.status.idle":"2025-06-14T15:25:27.576980Z","shell.execute_reply.started":"2025-06-14T15:25:27.567130Z","shell.execute_reply":"2025-06-14T15:25:27.576205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.layers import (Conv2D, DepthwiseConv2D, BatchNormalization, ReLU,\n                                     Add, Input, GlobalAveragePooling2D, Dropout, Dense)\n\ndef fused_mbconv(x, out_filters, expansion, stride):\n    in_filters = x.shape[-1]\n    hidden_dim = in_filters * expansion\n\n    x_input = x\n    x = Conv2D(hidden_dim, 3, strides=stride, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(out_filters, 1, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x = GAM()(x)\n\n    if stride == 1 and in_filters == out_filters:\n        x = Add()([x_input, x])\n    return x\n\ndef mbconv(x, out_filters, expansion, stride):\n    in_filters = x.shape[-1]\n    hidden_dim = in_filters * expansion\n\n    x_input = x\n    x = Conv2D(hidden_dim, 1, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = DepthwiseConv2D(3, strides=stride, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(out_filters, 1, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x = ECA()(x)\n\n    if stride == 1 and in_filters == out_filters:\n        x = Add()([x_input, x])\n    return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:25:27.577866Z","iopub.execute_input":"2025-06-14T15:25:27.578099Z","iopub.status.idle":"2025-06-14T15:25:27.591731Z","shell.execute_reply.started":"2025-06-14T15:25:27.578066Z","shell.execute_reply":"2025-06-14T15:25:27.591024Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_paper_lowflops_model(input_shape=(224, 224, 3), num_classes=4):\n    inputs = Input(shape=input_shape)\n    x = Conv2D(32, 3, strides=2, padding='same')(inputs)  # Smaller stem\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    # Updated reduced-width blocks\n    blocks = [\n        (1, 16, 2, 1, 'fused'),    # lower out_channels\n        (2, 24, 3, 2, 'fused'),\n        (2, 32, 3, 2, 'fused'),\n        (3, 64, 4, 2, 'mbconv'),\n        (3, 96, 6, 1, 'mbconv'),\n        (4, 160, 12, 2, 'mbconv'),\n        (4, 128, 2, 1, 'mbconv')\n    ]\n\n    for expansion, out_filters, repeats, stride, block_type in blocks:\n        for i in range(repeats):\n            s = stride if i == 0 else 1\n            if block_type == 'fused':\n                x = fused_mbconv(x, out_filters, expansion, s)\n            else:\n                x = mbconv(x, out_filters, expansion, s)\n\n    x = Conv2D(128, 1, padding='same')(x)  # Final bottleneck layer much smaller\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.3)(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    outputs = Dense(num_classes, activation='softmax')(x)\n\n    return tf.keras.Model(inputs, outputs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:25:27.592619Z","iopub.execute_input":"2025-06-14T15:25:27.592839Z","iopub.status.idle":"2025-06-14T15:25:27.606874Z","shell.execute_reply.started":"2025-06-14T15:25:27.592820Z","shell.execute_reply":"2025-06-14T15:25:27.606195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n\ndef get_flops(model, batch_size=1):\n    # Build the model if not already built\n    if not model.built:\n        model.build(input_shape=(batch_size, *model.input_shape[1:]))\n\n    # Get concrete function\n    concrete_func = tf.function(model).get_concrete_function(\n        tf.TensorSpec([batch_size, *model.input_shape[1:]], model.inputs[0].dtype)\n    )\n\n    # Convert to frozen concrete function\n    frozen_func = convert_variables_to_constants_v2(concrete_func)\n\n    # Use TF1 profiler API to calculate FLOPs\n    run_meta = tf.compat.v1.RunMetadata()\n    opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n\n    flops = tf.compat.v1.profiler.profile(\n        graph=frozen_func.graph,\n        run_meta=run_meta,\n        cmd='op',\n        options=opts\n    )\n\n    return flops.total_float_ops if flops is not None else 0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:25:27.610072Z","iopub.execute_input":"2025-06-14T15:25:27.610402Z","iopub.status.idle":"2025-06-14T15:25:27.624242Z","shell.execute_reply.started":"2025-06-14T15:25:27.610374Z","shell.execute_reply":"2025-06-14T15:25:27.623396Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_paper_lowflops_model()\nflops = get_flops(model, batch_size=1)\nparams = model.count_params()\n\nprint(\"=============================================\")\nprint(f\"🧮 FLOPs: {flops / 1e9:.03f} GFLOPs\")\nprint(f\"🔢 Parameters: {params:,}\")\nprint(\"=============================================\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:25:27.625312Z","iopub.execute_input":"2025-06-14T15:25:27.625602Z","iopub.status.idle":"2025-06-14T15:25:34.151068Z","shell.execute_reply.started":"2025-06-14T15:25:27.625581Z","shell.execute_reply":"2025-06-14T15:25:34.150119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def cbam_block(inputs, reduction_ratio=8):\n    channel = inputs.shape[-1]\n\n    # Channel Attention\n    avg_pool = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n    max_pool = tf.reduce_max(inputs, axis=[1, 2], keepdims=True)\n\n    dense1 = tf.keras.layers.Dense(channel // reduction_ratio, activation='relu', use_bias=False)\n    dense2 = tf.keras.layers.Dense(channel, use_bias=False)\n\n    avg_out = dense2(dense1(avg_pool))\n    max_out = dense2(dense1(max_pool))\n    scale = tf.keras.activations.sigmoid(avg_out + max_out)\n    x = tf.multiply(inputs, scale)\n\n    # Spatial Attention\n    avg_pool_spatial = tf.reduce_mean(x, axis=-1, keepdims=True)\n    max_pool_spatial = tf.reduce_max(x, axis=-1, keepdims=True)\n    concat = tf.concat([avg_pool_spatial, max_pool_spatial], axis=-1)\n    spatial = tf.keras.layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')(concat)\n    return tf.multiply(x, spatial)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:25:34.152282Z","iopub.execute_input":"2025-06-14T15:25:34.152670Z","iopub.status.idle":"2025-06-14T15:25:34.159120Z","shell.execute_reply.started":"2025-06-14T15:25:34.152643Z","shell.execute_reply":"2025-06-14T15:25:34.158312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fused_mbconv(x, out_filters, expansion, stride):\n    input_channels = x.shape[-1]\n    x = tf.keras.layers.Conv2D(input_channels * expansion, 3, strides=stride, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Conv2D(out_filters, 1, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = cbam_block(x)\n    return x\ndef mbconv(x, out_filters, expansion, stride):\n    input_channels = x.shape[-1]\n    \n    # Expansion phase\n    expanded = tf.keras.layers.Conv2D(input_channels * expansion, 1, padding='same')(x)\n    expanded = tf.keras.layers.BatchNormalization()(expanded)\n    expanded = tf.keras.layers.ReLU()(expanded)\n\n    # Depthwise convolution\n    depthwise = tf.keras.layers.DepthwiseConv2D(3, strides=stride, padding='same')(expanded)\n    depthwise = tf.keras.layers.BatchNormalization()(depthwise)\n    depthwise = tf.keras.layers.ReLU()(depthwise)\n\n    # Projection\n    projected = tf.keras.layers.Conv2D(out_filters, 1, padding='same')(depthwise)\n    projected = tf.keras.layers.BatchNormalization()(projected)\n    projected = cbam_block(projected)\n\n    # Residual connection\n    if stride == 1 and input_channels == out_filters:\n        return tf.keras.layers.Add()([x, projected])\n    else:\n        return projected\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:25:34.160253Z","iopub.execute_input":"2025-06-14T15:25:34.160828Z","iopub.status.idle":"2025-06-14T15:25:34.175723Z","shell.execute_reply.started":"2025-06-14T15:25:34.160805Z","shell.execute_reply":"2025-06-14T15:25:34.175025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetV2S\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout\n\ndef build_cbam_efficientnetv2s(input_shape=(224, 224, 3), num_classes=4):\n    inputs = Input(shape=input_shape)\n    x = Conv2D(32, 3, strides=2, padding='same')(inputs)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    blocks = [\n        (1, 16, 2, 1, 'fused'),\n        (2, 24, 3, 2, 'fused'),\n        (2, 32, 3, 2, 'fused'),\n        (3, 64, 4, 2, 'mbconv'),\n        (3, 96, 6, 1, 'mbconv'),\n        (4, 160, 12, 2, 'mbconv'),\n        (4, 128, 2, 1, 'mbconv')\n    ]\n\n    for expansion, out_filters, repeats, stride, block_type in blocks:\n        for i in range(repeats):\n            s = stride if i == 0 else 1\n            if block_type == 'fused':\n                x = fused_mbconv(x, out_filters, expansion, s)\n            else:\n                x = mbconv(x, out_filters, expansion, s)\n\n    x = Conv2D(128, 1, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.3)(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    outputs = Dense(num_classes, activation='softmax')(x)\n\n    return Model(inputs, outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:25:34.176504Z","iopub.execute_input":"2025-06-14T15:25:34.176720Z","iopub.status.idle":"2025-06-14T15:25:34.190975Z","shell.execute_reply.started":"2025-06-14T15:25:34.176699Z","shell.execute_reply":"2025-06-14T15:25:34.190357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_cbam_efficientnetv2s()\nflops = get_flops(model, batch_size=1)\nparams = model.count_params()\n\nprint(\"=============================================\")\nprint(f\"🧮 FLOPs: {flops / 1e9:.03f} GFLOPs\")\nprint(f\"🔢 Parameters: {params:,}\")\nprint(\"=============================================\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:25:34.191900Z","iopub.execute_input":"2025-06-14T15:25:34.192130Z","iopub.status.idle":"2025-06-14T15:25:43.566175Z","shell.execute_reply.started":"2025-06-14T15:25:34.192110Z","shell.execute_reply":"2025-06-14T15:25:43.565282Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! pip install imutils\n!pip install tensorflow\n\nimport tensorflow as tf\nfrom sklearn.utils.class_weight import compute_class_weight\nimport matplotlib.pyplot as plt\nimport imutils\nimport pathlib\nimport time\nimport PIL as pil\nimport shutil\nfrom tqdm import tqdm\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport gc\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport itertools\nimport joblib\n\n\n\nIMAGE_SIZE = (224, 224)\nBASE_LR = 2e-5\nEPOCH = 20\nBATCH_SIZE = 8","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:25:43.567437Z","iopub.execute_input":"2025-06-14T15:25:43.568115Z","iopub.status.idle":"2025-06-14T15:26:03.049241Z","shell.execute_reply.started":"2025-06-14T15:25:43.568080Z","shell.execute_reply":"2025-06-14T15:26:03.048221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install tensorflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:26:03.050680Z","iopub.execute_input":"2025-06-14T15:26:03.050950Z","iopub.status.idle":"2025-06-14T15:26:11.318894Z","shell.execute_reply.started":"2025-06-14T15:26:03.050925Z","shell.execute_reply":"2025-06-14T15:26:11.317984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def crop_img(img, image_size=(224, 224)):\n    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n\n    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n    thresh = cv2.erode(thresh, None, iterations=2)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    cnts = imutils.grab_contours(cnts)\n    \n    if len(cnts) == 0:\n        print(\"Warning: No contours found, returning resized original image.\")\n        return cv2.resize(img, image_size, interpolation=cv2.INTER_CUBIC)\n    \n    c = max(cnts, key=cv2.contourArea)\n\n    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n    extRight = tuple(c[c[:, :, 0].argmax()][0])\n    extTop = tuple(c[c[:, :, 1].argmin()][0])\n    extBot = tuple(c[c[:, :, 1].argmax()][0])\n\n    ADD_PIXELS = 0\n    new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n    new_img = cv2.resize(new_img, image_size, interpolation=cv2.INTER_CUBIC)\n    return new_img\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:26:11.320507Z","iopub.execute_input":"2025-06-14T15:26:11.320766Z","iopub.status.idle":"2025-06-14T15:26:11.329391Z","shell.execute_reply.started":"2025-06-14T15:26:11.320742Z","shell.execute_reply":"2025-06-14T15:26:11.328476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def image_preprocessing(source_dir, saved_root_dir, image_size=(224, 224), channels=3):\n    if not os.path.exists(source_dir):\n        raise Exception(f\"Source directory: {source_dir} does not exist\")\n    if not os.path.isdir(source_dir):\n        raise Exception(f\"Source path: {source_dir} is not a directory\")\n\n    if not os.path.exists(saved_root_dir):\n        os.makedirs(saved_root_dir)\n        \n    source_dir_path = pathlib.Path(source_dir)\n    \n    for p in tqdm(source_dir_path.iterdir(), desc=\"Processing folders\"):\n        dir_name = str(p).split(\"/\")[-1]\n        for fp in p.iterdir():\n            filename = str(fp).split(\"/\")[-1]\n\n            img = tf.io.read_file(str(fp))\n            img = tf.image.decode_jpeg(img, channels=channels)\n            img = crop_img(img.numpy(), image_size)\n            # img = cv2.imread(str(fp))\n            # if img is None:\n            #     continue\n\n            # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n            # # === Apply CLAHE enhancement ===\n            # gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n            # clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            # enhanced_gray = clahe.apply(gray)\n            # img = cv2.cvtColor(enhanced_gray, cv2.COLOR_GRAY2RGB)\n\n            # # === Apply cropping ===\n            # img = crop_img(img, image_size)\n\n            img = pil.Image.fromarray(img)\n\n            saved_dist_dir = os.path.join(saved_root_dir, dir_name)\n            if not os.path.exists(saved_dist_dir):\n                os.makedirs(saved_dist_dir)\n\n            img_dist_path = os.path.join(saved_dist_dir, filename)\n            img.save(img_dist_path)\n    print(f\"\\n✅ All images processed and saved to: {saved_root_dir}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:26:11.330623Z","iopub.execute_input":"2025-06-14T15:26:11.330936Z","iopub.status.idle":"2025-06-14T15:26:11.343631Z","shell.execute_reply.started":"2025-06-14T15:26:11.330905Z","shell.execute_reply":"2025-06-14T15:26:11.342828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_preprocessing(\n    \"/kaggle/input/brain-tumor-mri-dataset/Training\",\n    \"/kaggle/working/processed/Training\",\n    image_size=IMAGE_SIZE\n)\n\nimage_preprocessing(\n    \"/kaggle/input/brain-tumor-mri-dataset/Testing\",\n    \"/kaggle/working/processed/Testing\",\n    image_size=IMAGE_SIZE\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:26:11.344629Z","iopub.execute_input":"2025-06-14T15:26:11.344907Z","iopub.status.idle":"2025-06-14T15:27:20.726982Z","shell.execute_reply.started":"2025-06-14T15:26:11.344885Z","shell.execute_reply":"2025-06-14T15:27:20.726196Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Datasets","metadata":{"id":"YuJXo3b-f7PX"}},{"cell_type":"code","source":"root_dir_path = \"/kaggle/working/brain-tumor-mri-dataset\"","metadata":{"id":"nLLkxrD0ivtJ","trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:27:20.728315Z","iopub.execute_input":"2025-06-14T15:27:20.728900Z","iopub.status.idle":"2025-06-14T15:27:20.733199Z","shell.execute_reply.started":"2025-06-14T15:27:20.728867Z","shell.execute_reply":"2025-06-14T15:27:20.732243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = tf.keras.utils.image_dataset_from_directory(\n    \"/kaggle/working/processed/Training\",\n    label_mode=\"categorical\",\n    batch_size=BATCH_SIZE,\n    image_size=IMAGE_SIZE,\n    seed=42\n)\n\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n    \"/kaggle/working/processed/Testing\",\n    label_mode=\"categorical\",\n    batch_size=BATCH_SIZE,\n    image_size=IMAGE_SIZE,\n    shuffle=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:27:20.737984Z","iopub.execute_input":"2025-06-14T15:27:20.738213Z","iopub.status.idle":"2025-06-14T15:27:21.144239Z","shell.execute_reply.started":"2025-06-14T15:27:20.738193Z","shell.execute_reply":"2025-06-14T15:27:21.143589Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint(\"Class names:\", class_names)\n\ncls_to_id = {c: i for i, c in enumerate(class_names)}\nid_to_cls = {i: c for i, c in enumerate(class_names)}\nprint(\"cls_to_id:\", cls_to_id)\nprint(\"id_to_cls:\", id_to_cls)","metadata":{"id":"8Q3yArLCf7Pe","outputId":"6a76410d-f086-4531-b6cc-6599f0fb2512","trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:27:21.145272Z","iopub.execute_input":"2025-06-14T15:27:21.145591Z","iopub.status.idle":"2025-06-14T15:27:21.151010Z","shell.execute_reply.started":"2025-06-14T15:27:21.145561Z","shell.execute_reply":"2025-06-14T15:27:21.150057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ✅ Apply real-time data augmentation to training set only\ndata_augmentation = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(\"horizontal\"),\n    tf.keras.layers.RandomRotation(0.1),\n    tf.keras.layers.RandomZoom(0.1),\n])\n\ntrain_ds = train_ds.map(lambda x, y: (data_augmentation(x), y))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:27:21.152120Z","iopub.execute_input":"2025-06-14T15:27:21.152821Z","iopub.status.idle":"2025-06-14T15:27:21.480176Z","shell.execute_reply.started":"2025-06-14T15:27:21.152788Z","shell.execute_reply":"2025-06-14T15:27:21.479466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"class_to_id.txt\", \"w\") as f:\n    for k, v in cls_to_id.items():\n        f.write(f\"{k}\\t{v}\\n\")\n\nwith open(\"id_to_class.txt\", \"w\") as f:\n    for k, v in id_to_cls.items():\n        f.write(f\"{k}\\t{v}\\n\")","metadata":{"id":"uPjSeagdf7Pf","trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:27:21.481307Z","iopub.execute_input":"2025-06-14T15:27:21.481537Z","iopub.status.idle":"2025-06-14T15:27:21.486845Z","shell.execute_reply.started":"2025-06-14T15:27:21.481516Z","shell.execute_reply":"2025-06-14T15:27:21.485922Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"class_to_id.txt\", \"r\") as f:\n    for line in f.readlines():\n        cls, label = line.replace(\"\\n\",\"\").split(\"\\t\")\n        print(cls, int(label))\nprint(\"\\n\")\nwith open(\"id_to_class.txt\", \"r\") as f:\n    for line in f.readlines():\n        label, cls = line.replace(\"\\n\",\"\").split(\"\\t\")\n        print(int(label), cls)","metadata":{"id":"XLvvdUm6f7Pf","outputId":"b2aa2166-813d-42a6-fb31-2d166c69afbf","trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:27:21.487868Z","iopub.execute_input":"2025-06-14T15:27:21.488079Z","iopub.status.idle":"2025-06-14T15:27:21.499021Z","shell.execute_reply.started":"2025-06-14T15:27:21.488061Z","shell.execute_reply":"2025-06-14T15:27:21.498233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def class_weight_from_one_hot(ds):\n    class_labels = []\n    if ds.__class__.__name__ == \"_BatchDataset\":\n        ds = ds.unbatch()\n\n    for _, onehot in ds:\n        label = tf.argmax(onehot).numpy()\n        if label.shape == ():  # scalar\n            class_labels.append(label.item())\n        else:  # batch\n            class_labels.extend([l.item() for l in label])\n\n    unique_classes = np.unique(class_labels)\n    class_weights = compute_class_weight(class_weight=\"balanced\", \n                                         classes=unique_classes,\n                                         y=class_labels)\n    return {i: w for i, w in enumerate(class_weights)}\n\n\n    \nclass_weights = class_weight_from_one_hot(train_ds)\nprint(class_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:27:21.500130Z","iopub.execute_input":"2025-06-14T15:27:21.500790Z","iopub.status.idle":"2025-06-14T15:28:13.517557Z","shell.execute_reply.started":"2025-06-14T15:27:21.500766Z","shell.execute_reply":"2025-06-14T15:28:13.516674Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for images, labels in train_ds.take(1):\n    image, label = images[0], labels[0]\n    plt.figure()\n    plt.imshow(tf.cast(image, tf.uint8))\n    plt.title(class_names[tf.argmax(label).numpy()])\n    plt.axis(\"off\")\n    plt.show()\n","metadata":{"id":"f2EnMhWWf7Pf","outputId":"b33194ba-2d4f-4efa-ce72-84677d5d64ba","trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:28:13.518714Z","iopub.execute_input":"2025-06-14T15:28:13.519008Z","iopub.status.idle":"2025-06-14T15:28:13.993602Z","shell.execute_reply.started":"2025-06-14T15:28:13.518985Z","shell.execute_reply":"2025-06-14T15:28:13.992703Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{"id":"8XEQ_expf7Ph"}},{"cell_type":"code","source":"class PrintLR(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        lr = self.model.optimizer.lr\n        if hasattr(lr, 'numpy'):\n            print(f\"🔁 Epoch {epoch+1}: Learning rate = {lr.numpy():.6f}\")\n        else:\n            print(f\"🔁 Epoch {epoch+1}: Learning rate = {tf.keras.backend.get_value(lr):.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:28:13.994652Z","iopub.execute_input":"2025-06-14T15:28:13.994878Z","iopub.status.idle":"2025-06-14T15:28:13.999893Z","shell.execute_reply.started":"2025-06-14T15:28:13.994857Z","shell.execute_reply":"2025-06-14T15:28:13.999065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_lrfn(\n    lr_start=1e-4,\n    lr_max=5e-4,\n    lr_min=1e-6,\n    lr_rampup_epochs=5,\n    lr_sustain_epochs=5,\n    lr_exp_decay=0.8\n):\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:28:14.000896Z","iopub.execute_input":"2025-06-14T15:28:14.001234Z","iopub.status.idle":"2025-06-14T15:28:14.011763Z","shell.execute_reply.started":"2025-06-14T15:28:14.001211Z","shell.execute_reply":"2025-06-14T15:28:14.010930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\n# Remove previous best model file if it exists\nif os.path.exists(\"best_initial_model.keras\"):\n    os.remove(\"best_initial_model.keras\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:28:14.012709Z","iopub.execute_input":"2025-06-14T15:28:14.012952Z","iopub.status.idle":"2025-06-14T15:28:14.024404Z","shell.execute_reply.started":"2025-06-14T15:28:14.012933Z","shell.execute_reply":"2025-06-14T15:28:14.023681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nimport gc\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras import backend as K\nfrom collections import defaultdict\n\n# Assumes: BASE_LR, build_lrfn(), build_cbam_efficientnetv2s(), class_weights, train_ds, test_ds\n\n# Learning Rate Schedule\nlrfn = build_lrfn()\nlr_schedule = LearningRateScheduler(lrfn, verbose=True)\n\nclass PrintLR(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        lr = self.model.optimizer.lr\n        print(f\"Learning rate at epoch {epoch + 1} is: {K.get_value(lr):.6f}\")\n\nbase_cbs = [\n    EarlyStopping(patience=10, monitor='val_loss', restore_best_weights=True),\n    lr_schedule,\n    PrintLR()\n]\n\n# Convert tf.data.Dataset to numpy arrays\ndef dataset_to_numpy(ds):\n    data = list(ds.unbatch().as_numpy_iterator())\n    images = np.array([x[0] for x in data])\n    labels = np.array([x[1] for x in data])\n    return images, labels\n\nimages, labels = dataset_to_numpy(train_ds)\nlabel_indices = np.argmax(labels, axis=1)\n\n# Trackers\nbest_cbam_model = {\"fold\": None, \"train_accuracy\": 0, \"val_accuracy\": 0, \"test_accuracy\": 0, \"model\": None}\naccuracies = []\nhistory_storage = defaultdict(list)\n\n# Stratified K-Fold\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(images, label_indices)):\n    print(f\"\\n📂 Fold {fold + 1}\")\n\n    # Split data\n    X_train, X_val = images[train_idx], images[val_idx]\n    y_train, y_val = labels[train_idx], labels[val_idx]\n\n    train_fold_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(8).prefetch(tf.data.AUTOTUNE)\n    val_fold_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(8).prefetch(tf.data.AUTOTUNE)\n\n    checkpoint_path = f\"best_cbam_effnetv2s_fold{fold+1}.weights.h5\"\n    if os.path.exists(checkpoint_path):\n        os.remove(checkpoint_path)\n\n    model_checkpoint = ModelCheckpoint(\n        checkpoint_path,\n        monitor='val_categorical_accuracy',\n        save_best_only=True,\n        mode='max',\n        save_weights_only=True\n    )\n\n    cbam_model = build_cbam_efficientnetv2s()\n    cbam_model.compile(\n        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05),\n        optimizer=tf.keras.optimizers.Adam(BASE_LR),\n        metrics=[\"categorical_accuracy\"]\n    )\n\n    history = cbam_model.fit(\n        train_fold_ds,\n        validation_data=val_fold_ds,\n        epochs=40,\n        callbacks=base_cbs + [model_checkpoint],\n        class_weight=class_weights,\n        verbose=1\n    )\n\n    cbam_model.load_weights(checkpoint_path)\n\n    for metric in history.history:\n        history_storage[metric].append(history.history[metric])\n\n    test_acc = cbam_model.evaluate(test_ds, verbose=0)[1]\n    accuracies.append(test_acc)\n\n    if test_acc > best_cbam_model[\"test_accuracy\"]:\n        best_cbam_model = {\n            \"fold\": fold + 1,\n            \"train_accuracy\": max(history.history['categorical_accuracy']),\n            \"val_accuracy\": max(history.history['val_categorical_accuracy']),\n            \"test_accuracy\": test_acc,\n            \"model\": cbam_model\n        }\n\n    K.clear_session()\n    gc.collect()\n\n    print(f\"\\n✅ Fold {fold + 1} Results:\")\n    print(f\"Test Accuracy: {test_acc:.4f}\")\n\n# Final Summary\nprint(\"\\n🏆 Best Fold:\", best_cbam_model[\"fold\"])\nprint(f\"Train Accuracy: {best_cbam_model['train_accuracy']:.4f}\")\nprint(f\"Validation Accuracy: {best_cbam_model['val_accuracy']:.4f}\")\nprint(f\"Test Accuracy: {best_cbam_model['test_accuracy']:.4f}\")\nprint(f\"Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n\n# Save best model weights\nbest_cbam_model[\"model\"].save_weights(\"best_cbam_effnetv2s_model.weights.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:28:14.025707Z","iopub.execute_input":"2025-06-14T15:28:14.026008Z","iopub.status.idle":"2025-06-14T15:35:30.169674Z","shell.execute_reply.started":"2025-06-14T15:28:14.025980Z","shell.execute_reply":"2025-06-14T15:35:30.168909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\n\n# Unpack the best model and load its weights\nmodel = best_cbam_model[\"model\"]\nmodel.load_weights(\"best_cbam_effnetv2s_model.weights.h5\")\n\n# Convert test_ds to numpy for prediction\ndef dataset_to_numpy(ds):\n    data = list(ds.unbatch().as_numpy_iterator())\n    images = np.array([x[0] for x in data])\n    labels = np.array([x[1] for x in data])\n    return images, labels\n\ntest_images, test_labels = dataset_to_numpy(test_ds)\ny_true = np.argmax(test_labels, axis=1)\ny_pred = np.argmax(model.predict(test_images, batch_size=8), axis=1)\n\n# Confusion matrix\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Glioma\", \"Meningioma\", \"No Tumor\", \"Pituitary\"],\n            yticklabels=[\"Glioma\", \"Meningioma\", \"No Tumor\", \"Pituitary\"])\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix - CBAM EfficientNetV2S')\nplt.show()\n\n# Classification Report\nreport = classification_report(y_true, y_pred, target_names=[\"Glioma\", \"Meningioma\", \"No Tumor\", \"Pituitary\"])\nprint(\"Classification Report:\\n\", report)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:35:30.173228Z","iopub.execute_input":"2025-06-14T15:35:30.173497Z","iopub.status.idle":"2025-06-14T15:35:47.723917Z","shell.execute_reply.started":"2025-06-14T15:35:30.173474Z","shell.execute_reply":"2025-06-14T15:35:47.723038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\ntrain_acc = history_storage[\"categorical_accuracy\"][best_cbam_model[\"fold\"] - 1]\nval_acc = history_storage[\"val_categorical_accuracy\"][best_cbam_model[\"fold\"] - 1]\ntrain_loss = history_storage[\"loss\"][best_cbam_model[\"fold\"] - 1]\nval_loss = history_storage[\"val_loss\"][best_cbam_model[\"fold\"] - 1]\n\nepochs = range(1, len(train_acc) + 1)\n\nplt.figure(figsize=(12, 5))\n\n# Accuracy plot\nplt.subplot(1, 2, 1)\nplt.plot(epochs, train_acc, label='Training Accuracy')\nplt.plot(epochs, val_acc, label='Validation Accuracy')\nplt.title('Training vs Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(epochs, train_loss, label='Training Loss')\nplt.plot(epochs, val_loss, label='Validation Loss')\nplt.title('Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:35:47.725370Z","iopub.execute_input":"2025-06-14T15:35:47.726057Z","iopub.status.idle":"2025-06-14T15:35:48.114445Z","shell.execute_reply.started":"2025-06-14T15:35:47.726020Z","shell.execute_reply":"2025-06-14T15:35:48.113640Z"}},"outputs":[],"execution_count":null}]}